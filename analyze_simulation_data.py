"""
ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿãƒ‡ãƒ¼ã‚¿è§£æãƒ»å¯è¦–åŒ–å‡¦ç†

ç”Ÿãƒ‡ãƒ¼ã‚¿ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ã€
ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰ã¨åŒã˜å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã™ã‚‹
"""

"""
ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿãƒ‡ãƒ¼ã‚¿è§£æãƒ»å¯è¦–åŒ–å‡¦ç†

ç”Ÿãƒ‡ãƒ¼ã‚¿ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ã€
ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰ã¨åŒã˜å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã™ã‚‹
"""

# Standard library imports
import json
import os
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional
import xml.etree.ElementTree as ET

# Third-party imports
import numpy as np

# Local imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from src.config import SimulationConfig
from src.simulation.graph_generator import GraphGenerator
from src.visualization import TrajectoryVisualizer, SegmentStorageVisualizer
from common import get_file_timestamp


class FileUtils:
    """ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¯ãƒ©ã‚¹"""
    
    @staticmethod
    def find_available_data_files(results_dir: str = "results", max_files: int = 5) -> List[Path]:
        """åˆ©ç”¨å¯èƒ½ãªç”Ÿãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ã™ã‚‹
        
        Args:
            results_dir: æ¤œç´¢å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            max_files: æœ€å¤§è¡¨ç¤ºä»¶æ•°
            
        Returns:
            List[Path]: è¦‹ã¤ã‹ã£ãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
        """
        files = []
        if os.path.exists(results_dir):
            for subdir in sorted(os.listdir(results_dir), reverse=True)[:max_files]:
                subdir_path = os.path.join(results_dir, subdir)
                if os.path.isdir(subdir_path):
                    json_files = list(Path(subdir_path).glob('raw_simulation_data_*.json'))
                    if json_files:
                        files.append(json_files[0])
        return files
    
    @staticmethod
    def load_json_data(file_path: str) -> Optional[Dict]:
        """JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        
        Args:
            file_path: JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            
        Returns:
            Optional[Dict]: èª­ã¿è¾¼ã¾ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã€å¤±æ•—æ™‚ã¯None
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return None


class MatrixDifferenceCalculator:
    """è¡Œåˆ—å·®åˆ†è¨ˆç®—ã‚’æ‹…å½“ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, step_data: List[Dict]):
        self.step_data = step_data
        self.true_transition_matrix = self._extract_true_matrix()
    
    def _extract_true_matrix(self) -> Optional[np.ndarray]:
        """æœ€æ–°ã®çœŸã®é·ç§»è¡Œåˆ—ã‚’å–å¾—"""
        for step_info in reversed(self.step_data):
            true_matrix = step_info['scheduler']['true_transition_matrix']
            if true_matrix is not None:
                return np.array(true_matrix)
        return None
    
    def calculate_matrix_differences(self) -> List[Dict]:
        """ä¿å­˜ã•ã‚ŒãŸselected_transition_matrix_historyã‚’ä½¿ç”¨ã—ã¦è¡Œåˆ—å·®åˆ†ã‚’è¨ˆç®—"""
        if self.true_transition_matrix is None:
            return []
        
        differences = []
        all_selected_matrices = []
        
        # å„ã‚¹ãƒ†ãƒƒãƒ—ã®selected_transition_matrix_historyã‚’åé›†
        for step_info in self.step_data:
            history = step_info['scheduler'].get('selected_transition_matrix_history', [])
            all_selected_matrices.extend(history)
        
        # é‡è¤‡ã‚’é™¤å»ï¼ˆåŒã˜stepã®ã‚¨ãƒ³ãƒˆãƒªã¯æœ€å¾Œã®ã‚‚ã®ã®ã¿ä½¿ç”¨ï¼‰
        unique_matrices = {}
        for history_entry in all_selected_matrices:
            step = history_entry['step']
            unique_matrices[step] = history_entry
        
        # stepã§ã‚½ãƒ¼ãƒˆã—ã¦å·®åˆ†ã‚’è¨ˆç®—
        for step in sorted(unique_matrices.keys()):
            history_entry = unique_matrices[step]
            selected_matrix = history_entry['matrix']
            
            # è¡Œåˆ—ã®å·®ã‚’è¨ˆç®—ï¼ˆãƒ•ãƒ­ãƒ™ãƒ‹ã‚¦ã‚¹ãƒãƒ«ãƒ ï¼‰
            if isinstance(selected_matrix, list):
                selected_matrix = np.array(selected_matrix)
            
            diff_matrix = self.true_transition_matrix - selected_matrix
            frobenius_norm = np.linalg.norm(diff_matrix, 'fro')
            
            differences.append({
                'step': step,
                'frobenius_norm': frobenius_norm,
                'max_absolute_diff': np.max(np.abs(diff_matrix))
            })
        
        return differences


class AnalysisConfig:
    """è§£æè¨­å®šã‚¯ãƒ©ã‚¹

    - XMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è§£æè¨­å®šã‚’èª­ã¿è¾¼ã‚€
    - ç”Ÿãƒ‡ãƒ¼ã‚¿ã®å ´æ‰€ã¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§æŒ‡å®šï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä¾å­˜ã‚’å»ƒæ­¢ï¼‰
    - å„è§£æå‡ºåŠ›ï¼ˆã‚°ãƒ©ãƒ•/ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³/ã‚µãƒãƒªï¼‰ã‚’å€‹åˆ¥ã«åˆ¶å¾¡
    """

    def __init__(self) -> None:
        # å…¥åŠ›
        self.raw_data_dir: Optional[str] = None
        self.raw_data_file: Optional[str] = None  # å®Ÿéš›ã«ä½¿ç”¨ã™ã‚‹JSONãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆraw_data_dirã‹ã‚‰è‡ªå‹•æ¤œå‡ºï¼‰

        # å‡ºåŠ›
        self.output_dir: Optional[str] = None  # Noneã®å ´åˆã€è‡ªå‹•ç”Ÿæˆï¼ˆè§£æå®Ÿè¡Œæ™‚åˆ»ï¼‰

        # å‡ºåŠ›ãƒ•ãƒ©ã‚°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ã™ã¹ã¦æœ‰åŠ¹ï¼‰
        self.generate_trajectory_graph: bool = True
        self.generate_total_value_graphs: bool = True
        self.generate_matrix_difference_graph: bool = True
        self.generate_text_summary: bool = True
        self.generate_trajectory_animation: bool = False
        self.generate_segment_storage_animation: bool = True

    @staticmethod
    def _to_bool(text: Optional[str], default: bool = True) -> bool:
        if text is None:
            return default
        return text.strip().lower() in {"1", "true", "yes", "on"}

    @classmethod
    def from_xml(cls, xml_path: str) -> "AnalysisConfig":
        """XMLè¨­å®šã‹ã‚‰ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç”Ÿæˆ"""
        config = cls()

        if not os.path.exists(xml_path):
            raise FileNotFoundError(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {xml_path}")

        tree = ET.parse(xml_path)
        root = tree.getroot()

        # å…¥åŠ›ï¼ˆç”Ÿãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª/ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
        input_node = root.find("input")
        if input_node is not None:
            raw_dir = input_node.findtext("raw_data_dir")
            config.raw_data_dir = raw_dir.strip() if raw_dir else None
            raw_file = input_node.findtext("raw_data_file")
            config.raw_data_file = raw_file.strip() if raw_file else None
        else:
            # å¾Œæ–¹äº’æ›: ãƒ«ãƒ¼ãƒˆç›´ä¸‹
            raw_dir = root.findtext("raw_data_dir")
            config.raw_data_dir = raw_dir.strip() if raw_dir else None

        # å‡ºåŠ›ï¼ˆæ˜ç¤ºæŒ‡å®šãŒã‚ã‚Œã°ä½¿ç”¨ï¼‰
        output_node = root.find("output")
        if output_node is not None:
            out_dir = output_node.findtext("dir")
            config.output_dir = out_dir.strip() if out_dir else None

        # å„å‡ºåŠ›ãƒ•ãƒ©ã‚°
        outputs_node = root.find("outputs")
        if outputs_node is not None:
            config.generate_trajectory_graph = cls._to_bool(outputs_node.findtext("trajectory_graph"), True)
            config.generate_total_value_graphs = cls._to_bool(outputs_node.findtext("total_value_graphs"), True)
            config.generate_matrix_difference_graph = cls._to_bool(outputs_node.findtext("matrix_difference_graph"), True)
            config.generate_text_summary = cls._to_bool(outputs_node.findtext("text_summary"), True)
            config.generate_trajectory_animation = cls._to_bool(outputs_node.findtext("trajectory_animation"), False)
            config.generate_segment_storage_animation = cls._to_bool(outputs_node.findtext("segment_storage_animation"), True)

        # raw_data_file ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚Œã°å„ªå…ˆ
        if config.raw_data_file:
            candidate_paths: List[Path] = []
            file_text = config.raw_data_file
            p = Path(file_text)
            if p.is_absolute():
                candidate_paths.append(p)
            else:
                # ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç›´ä¸‹
                candidate_paths.append(Path(file_text))
                # raw_data_dir ãŒã‚ã‚Œã°çµåˆ
                if config.raw_data_dir:
                    candidate_paths.append(Path(config.raw_data_dir) / file_text)

            resolved = None
            for cp in candidate_paths:
                if cp.exists():
                    resolved = cp
                    break
            if not resolved:
                raise FileNotFoundError(f"æŒ‡å®šã•ã‚ŒãŸ raw_data_file ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_text}")

            config.raw_data_file = str(resolved)
            # raw_data_dir ãŒæœªæŒ‡å®šãªã‚‰ã€ãƒ•ã‚¡ã‚¤ãƒ«ã®è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®š
            if not config.raw_data_dir:
                config.raw_data_dir = str(Path(config.raw_data_file).parent)
        else:
            # raw_data_dir ã‹ã‚‰ JSON ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç‰¹å®šï¼ˆè‡ªå‹•æ¤œå‡ºï¼‰
            if not config.raw_data_dir:
                raise ValueError("raw_data_dir ã‹ raw_data_file ã®ã©ã¡ã‚‰ã‹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
            if not os.path.isdir(config.raw_data_dir):
                raise NotADirectoryError(f"raw_data_dir ãŒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ã¯ã‚ã‚Šã¾ã›ã‚“: {config.raw_data_dir}")

            candidates = list(Path(config.raw_data_dir).glob("raw_simulation_data_*.json"))
            if not candidates:
                raise FileNotFoundError(
                    f"raw_data_dir ã«ç”Ÿãƒ‡ãƒ¼ã‚¿JSONãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config.raw_data_dir}"
                )
            # è¤‡æ•°ã‚ã‚‹å ´åˆã¯æœ€çµ‚æ›´æ–°ãŒæ–°ã—ã„ã‚‚ã®ã‚’æ¡ç”¨
            candidates.sort(key=lambda p: p.stat().st_mtime, reverse=True)
            config.raw_data_file = str(candidates[0])

        return config


class SimulationDataAnalyzer:
    """ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿãƒ‡ãƒ¼ã‚¿è§£æãƒ»å¯è¦–åŒ–ã‚¯ãƒ©ã‚¹
    
    Args:
        raw_data_file: è§£æå¯¾è±¡ã®ç”Ÿãƒ‡ãƒ¼ã‚¿JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆNoneã®å ´åˆã¯è‡ªå‹•ç”Ÿæˆï¼‰
    """
    
    def __init__(self, raw_data_file: str, output_dir: Optional[str] = None) -> None:
        self.raw_data_file: str = raw_data_file
        self.raw_data: Optional[Dict] = None
        self.metadata: Optional[Dict] = None
        self.step_data: Optional[List[Dict]] = None
        self.config: Optional[SimulationConfig] = None
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
        if output_dir:
            self.output_dir = output_dir
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«analysis_ã‹ã‚‰å§‹ã¾ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
            base_dir = os.path.dirname(raw_data_file)
            timestamp = get_file_timestamp()
            self.output_dir = os.path.join(base_dir, f"analysis_{timestamp}")
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        os.makedirs(self.output_dir, exist_ok=True)
        
    def load_raw_data(self) -> bool:
        """ç”Ÿãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        
        Returns:
            bool: èª­ã¿è¾¼ã¿æˆåŠŸæ™‚Trueã€å¤±æ•—æ™‚False
        """
        self.raw_data = FileUtils.load_json_data(self.raw_data_file)
        
        if self.raw_data is None:
            return False
        
        self.metadata = self.raw_data['metadata']
        self.step_data = self.raw_data['step_data']
        
        # è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å¾©å…ƒ
        self.config = self._restore_config()
        
        print(f"âœ… ç”Ÿãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {self.raw_data_file}")
        print(f"   ã‚¹ãƒ†ãƒƒãƒ—æ•°: {len(self.step_data)}")
        print(f"   æˆ¦ç•¥: {self.metadata['config']['scheduling_strategy']}")
        print(f"   ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°: {self.metadata['config']['num_workers']}")
        print(f"   çŠ¶æ…‹æ•°: {self.metadata['config']['num_states']}")
        
        return True
    
    def _restore_config(self) -> SimulationConfig:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰SimulationConfigã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å¾©å…ƒ
        
        Returns:
            SimulationConfig: å¾©å…ƒã•ã‚ŒãŸè¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        """
        config_data = self.metadata['config']
        
        # SimulationConfigã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        config = SimulationConfig()
        
        # å±æ€§ã‚’è¨­å®š
        for key, value in config_data.items():
            setattr(config, key, value)
        
        return config
    
    def generate_all_visualizations(self, config: AnalysisConfig) -> None:
        """å…¨ã¦ã®å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
        
        Args:
            config: è§£æè¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        """
        print("\n=== å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆé–‹å§‹ ===")
        
        # è§£æãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
        analysis_data = self._prepare_analysis_data()
        
        # ã‚°ãƒ©ãƒ•ç”Ÿæˆå™¨ã‚’åˆæœŸåŒ–
        timestamp = self.metadata['timestamp']
        graph_generator = GraphGenerator(self.config, self.output_dir, timestamp)
        
        # 1. trajectoryé•·ã®æ¨ç§»ã‚°ãƒ©ãƒ•
        if config.generate_trajectory_graph:
            self._generate_trajectory_graph(graph_generator, analysis_data)
        
        # 2. total_valueé–¢é€£ã®ã‚°ãƒ©ãƒ•
        if config.generate_total_value_graphs:
            self._generate_total_value_graphs(graph_generator, analysis_data)
        
        # 3. è¡Œåˆ—å·®åˆ†ã®ã‚°ãƒ©ãƒ•
        if config.generate_matrix_difference_graph:
            self._generate_matrix_difference_graph(graph_generator, analysis_data)
        
        # 4. trajectoryå¯è¦–åŒ–ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³
        if config.generate_trajectory_animation:
            self._generate_trajectory_animation(analysis_data)
        
        # 5. ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³
        if config.generate_segment_storage_animation:
            self._generate_segment_storage_animation(analysis_data)
        
        # 6. ãƒ†ã‚­ã‚¹ãƒˆã‚µãƒãƒªãƒ¼
        if config.generate_text_summary:
            self._generate_text_summary(analysis_data)
        
        print(f"âœ… å…¨ã¦ã®å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {self.output_dir}")
    
    def _prepare_analysis_data(self) -> Dict[str, Any]:
        """è§£æã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
        
        Returns:
            Dict[str, Any]: è§£æç”¨ãƒ‡ãƒ¼ã‚¿ã®è¾æ›¸
        """
        trajectory_data = self._extract_trajectory_data()
        matrix_data = self._extract_matrix_data()
        segment_data = self._extract_segment_storage_data()
        
        return {
            **trajectory_data,
            **matrix_data,
            **segment_data
        }
    
    def _extract_trajectory_data(self) -> Dict[str, List]:
        """trajectoryã«é–¢é€£ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        
        Returns:
            Dict[str, List]: trajectoryé–¢é€£ãƒ‡ãƒ¼ã‚¿ã®è¾æ›¸
        """
        trajectory_lengths = []
        total_values_per_worker = []
        trajectory_states_list = []
        step_logs = []
        
        for step_data in self.step_data:
            # trajectoryé•· (ãƒ‡ãƒ¼ã‚¿ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼ã§æ—¢ã«-1æ¸ˆã¿)
            trajectory_states = step_data['splicer']['trajectory']
            trajectory_length = step_data['splicer']['trajectory_length']
            trajectory_lengths.append(trajectory_length)
            
            # trajectoryçŠ¶æ…‹
            trajectory_states_list.append(trajectory_states)
            
            # total_value per worker
            total_value = step_data['scheduler']['total_value']
            total_value_per_worker = total_value / self.config.num_workers if self.config.num_workers > 0 else 0
            total_values_per_worker.append(total_value_per_worker)
            
            # ã‚¹ãƒ†ãƒƒãƒ—ãƒ­ã‚°
            step_logs.append(step_data['step_log'])
        
        return {
            'trajectory_lengths': trajectory_lengths,
            'total_values_per_worker': total_values_per_worker,
            'trajectory_states_list': trajectory_states_list,
            'step_logs': step_logs
        }
    
    def _extract_matrix_data(self) -> Dict[str, Any]:
        """é·ç§»è¡Œåˆ—ã«é–¢é€£ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        
        Returns:
            Dict[str, Any]: é·ç§»è¡Œåˆ—é–¢é€£ãƒ‡ãƒ¼ã‚¿ã®è¾æ›¸
        """
        estimated_matrices = []
        true_matrix = np.array(self.metadata['transition_matrix'])
        
        for step_data in self.step_data:
            # æ¨å®šç¢ºç‡é·ç§»è¡Œåˆ—
            estimated_matrix = step_data['scheduler']['estimated_transition_matrix']
            if estimated_matrix:
                estimated_matrices.append(np.array(estimated_matrix))
            else:
                estimated_matrices.append(None)
        
        return {
            'estimated_matrices': estimated_matrices,
            'true_matrix': true_matrix
        }
    
    def _extract_segment_storage_data(self) -> Dict[str, List]:
        """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„ã«é–¢é€£ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        
        Returns:
            Dict[str, List]: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„é–¢é€£ãƒ‡ãƒ¼ã‚¿ã®è¾æ›¸
        """
        segment_storage_history = []
        
        for step_data in self.step_data:
            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
            segment_storage_record = self._prepare_segment_storage_record(step_data)
            segment_storage_history.append(segment_storage_record)
        
        return {
            'segment_storage_history': segment_storage_history
        }
    
    def _prepare_segment_storage_record(self, step_data: Dict) -> Dict[str, Any]:
        """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„å¯è¦–åŒ–ç”¨ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’æº–å‚™"""
        splicer_data = step_data['splicer']
        producer_data = step_data['producer']
        step_log = step_data['step_log']
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°æƒ…å ±
        segments_per_state = splicer_data['segment_store_info'].get('segments_per_state', {})
        
        # ã‚°ãƒ«ãƒ¼ãƒ—æƒ…å ±ã®å¤‰æ›
        group_info = {}
        for group_id, group_data in producer_data['group_details'].items():
            group_info[int(group_id)] = {
                'initial_state': group_data.get('initial_state'),
                'group_state': group_data.get('group_state'),
                'worker_ids': group_data.get('worker_ids', [])
            }
        
        # Spliceræƒ…å ±
        splicer_info = {
            'trajectory_length': splicer_data['trajectory_length'],
            'final_state': splicer_data['final_state'],
            'available_states': splicer_data['segment_store_info'].get('available_states', []),
            'used_segment_ids': splicer_data['segment_store_info'].get('used_segment_ids', {}),
            'total_used_segments': sum(len(ids) for ids in splicer_data['segment_store_info'].get('used_segment_ids', {}).values()),
            'states_with_segments': len(splicer_data['segment_store_info'].get('available_states', []))
        }
        
        return {
            'step': step_log['step'],
            'segments_per_state': segments_per_state,
            'group_info': group_info,
            'splicer_info': splicer_info,
            'total_segments': sum(segments_per_state.values())
        }
    
    def _generate_trajectory_graph(self, graph_generator: GraphGenerator, analysis_data: Dict) -> None:
        """trajectoryé•·ã®æ¨ç§»ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ"""
        print("  - trajectoryé•·æ¨ç§»ã‚°ãƒ©ãƒ•ç”Ÿæˆä¸­...")
        graph_generator.save_trajectory_graph(analysis_data['trajectory_lengths'])
    
    def _generate_total_value_graphs(self, graph_generator: GraphGenerator, analysis_data: Dict) -> None:
        """total_valueé–¢é€£ã®ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ"""
        print("  - total_valueé–¢é€£ã‚°ãƒ©ãƒ•ç”Ÿæˆä¸­...")
        graph_generator.save_total_value_graphs(
            analysis_data['total_values_per_worker'],
            analysis_data['trajectory_lengths']
        )
    
    def _generate_matrix_difference_graph(self, graph_generator: GraphGenerator, analysis_data: Dict) -> None:
        """è¡Œåˆ—å·®åˆ†ã®ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ"""
        print("  - è¡Œåˆ—å·®åˆ†ã‚°ãƒ©ãƒ•ç”Ÿæˆä¸­...")
        
        # MatrixDifferenceCalculatorã‚’ä½¿ç”¨ã—ã¦è¡Œåˆ—å·®åˆ†ã‚’è¨ˆç®—
        calculator = MatrixDifferenceCalculator(self.step_data)
        graph_generator.save_matrix_difference_graph(calculator)
    
    def _generate_trajectory_animation(self, analysis_data: Dict) -> None:
        """trajectoryå¯è¦–åŒ–ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ"""
        print("  - trajectoryå¯è¦–åŒ–ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆä¸­...")
        
        # trajectoryçŠ¶æ…‹å±¥æ­´ã¨é·ç§»è¡Œåˆ—ã‚’å–å¾—
        if analysis_data['trajectory_states_list'] and analysis_data['true_matrix'] is not None:
            trajectory_states_history = analysis_data['trajectory_states_list']
            transition_matrix = analysis_data['true_matrix']
            
            # TrajectoryVisualizerã‚’åˆæœŸåŒ–
            visualizer = TrajectoryVisualizer(self.config)
            visualizer.results_dir = self.output_dir
            visualizer.timestamp = self.metadata['timestamp']
            
            # ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆ
            visualizer.create_trajectory_animation(trajectory_states_history, transition_matrix)
    
    def _generate_segment_storage_animation(self, analysis_data: Dict) -> None:
        """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ"""
        print("  - ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆä¸­...")
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„å±¥æ­´ã‚’ step_data ã‹ã‚‰æŠ½å‡º
        segment_storage_history = []
        for step_info in self.step_data:
            if 'segment_storage' in step_info:
                segment_storage_history.append(step_info['segment_storage'])
        
        if not segment_storage_history:
            print("    âš ï¸ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„å±¥æ­´ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            return
        
        # SegmentStorageVisualizerã‚’åˆæœŸåŒ–
        visualizer = SegmentStorageVisualizer(self.config)
        visualizer.results_dir = self.output_dir
        visualizer.timestamp = self.metadata['timestamp']
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„å±¥æ­´ã‚’è¨­å®š
        visualizer.segment_history = segment_storage_history
        
        # ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆ
        output_file = visualizer.create_segment_storage_animation()
        if output_file:
            print(f"    âœ… ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³: {os.path.basename(output_file)}")
        else:
            print("    âŒ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    def _calculate_trajectory_coordinates(self, trajectory_states: List[int]) -> List[tuple]:
        """trajectoryçŠ¶æ…‹ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯åº§æ¨™ã‚’è¨ˆç®—"""
        if not trajectory_states:
            return []
        
        coordinates = [(0, 0)]  # é–‹å§‹ä½ç½®
        x, y = 0, 0
        
        # ç°¡å˜ãªãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        np.random.seed(42)  # å†ç¾æ€§ã®ãŸã‚
        
        for i in range(1, len(trajectory_states)):
            # æ¬¡ã®åº§æ¨™ã‚’è¨ˆç®—ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ãªæ–¹å‘ï¼‰
            angle = np.random.uniform(0, 2 * np.pi)
            step_size = 1.0
            x += step_size * np.cos(angle)
            y += step_size * np.sin(angle)
            coordinates.append((x, y))
        
        return coordinates
    
    def _generate_text_summary(self, analysis_data: Dict) -> None:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ"""
        print("  - ãƒ†ã‚­ã‚¹ãƒˆã‚µãƒãƒªãƒ¼ç”Ÿæˆä¸­...")
        
        filename = os.path.join(
            self.output_dir,
            f'analysis_summary_{self.config.scheduling_strategy}_{self.metadata["timestamp"]}.txt'
        )
        
        with open(filename, 'w', encoding='utf-8') as f:
            self._write_analysis_header(f)
            self._write_analysis_configuration(f)
            self._write_analysis_step_logs(f, analysis_data)
            self._write_analysis_summary_statistics(f, analysis_data)
    
    def _write_analysis_header(self, f) -> None:
        """è§£æãƒ¬ãƒãƒ¼ãƒˆã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æ›¸ãè¾¼ã‚€"""
        f.write("ParSplice ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è§£æçµæœ\n")
        f.write("=" * 50 + "\n")
        f.write(f"è§£æå®Ÿè¡Œæ™‚åˆ»: {get_file_timestamp()}\n")
        f.write(f"å…ƒãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«: {os.path.basename(self.raw_data_file)}\n")
        f.write(f"å…ƒãƒ‡ãƒ¼ã‚¿å®Ÿè¡Œæ™‚åˆ»: {self.metadata['execution_time']}\n\n")
    
    def _write_analysis_configuration(self, f) -> None:
        """è¨­å®šæƒ…å ±ã‚’æ›¸ãè¾¼ã‚€"""
        config = self.metadata['config']
        f.write("ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š:\n")
        f.write(f"  æˆ¦ç•¥: {config['scheduling_strategy']}\n")
        f.write(f"  ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°: {config['num_workers']}\n")
        f.write(f"  çŠ¶æ…‹æ•°: {config['num_states']}\n")
        f.write(f"  ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ™‚é–“: {config['max_simulation_time']}\n")
        f.write(f"  ä¹±æ•°ã‚·ãƒ¼ãƒ‰: {config['random_seed']}\n\n")
    
    def _write_analysis_step_logs(self, f, analysis_data: Dict) -> None:
        """ã‚¹ãƒ†ãƒƒãƒ—ãƒ­ã‚°ã‚’æ›¸ãè¾¼ã‚€"""
        f.write("ã‚¹ãƒ†ãƒƒãƒ—ãƒ­ã‚°:\n")
        for step_log in analysis_data['step_logs']:
            f.write(f"Step {step_log['step']}: Splicer={step_log['splicer_result']}, "
                   f"Scheduler={step_log['scheduler_result']}, "
                   f"Trajectoryé•·={step_log['trajectory_length']}, "
                   f"æœ€çµ‚çŠ¶æ…‹={step_log['final_state']}, "
                   f"åé›†segments={step_log['segments_collected']}\n")
            
            # ParRepBoxè©³ç´°æƒ…å ±
            parrepbox_info = []
            for box_detail in step_log['parrepbox_details']:
                parrepbox_info.append(
                    f"G{box_detail['group_id']}({box_detail['state']}, "
                    f"åˆæœŸ:{box_detail['initial_state']}, {box_detail['workers']})"
                )
            
            if parrepbox_info:
                f.write(f"  ParRepBox: {' | '.join(parrepbox_info)}\n")
            else:
                f.write(f"  ParRepBox: ãªã—\n")
        f.write("\n")
    
    def _write_analysis_summary_statistics(self, f, analysis_data: Dict) -> None:
        """æ¦‚è¦çµ±è¨ˆã‚’æ›¸ãè¾¼ã‚€"""
        trajectory_lengths = analysis_data['trajectory_lengths']
        total_values = analysis_data['total_values_per_worker']
        
        f.write("æ¦‚è¦çµ±è¨ˆ:\n")
        f.write(f"  æœ€çµ‚trajectoryé•·: {trajectory_lengths[-1] if trajectory_lengths else 0}\n")
        f.write(f"  æœ€çµ‚total_value_per_worker: {total_values[-1] if total_values else 0:.6f}\n")
        f.write(f"  å¹³å‡trajectoryé•·: {np.mean(trajectory_lengths) if trajectory_lengths else 0:.2f}\n")
        f.write(f"  å¹³å‡total_value_per_worker: {np.mean(total_values) if total_values else 0:.6f}\n")
        f.write(f"  æœ€å¤§trajectoryé•·: {max(trajectory_lengths) if trajectory_lengths else 0}\n")
        f.write(f"  æœ€å¤§total_value_per_worker: {max(total_values) if total_values else 0:.6f}\n")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("=" * 60)
    print("ParSpliceç”Ÿãƒ‡ãƒ¼ã‚¿è§£æãƒ»å¯è¦–åŒ–ãƒ„ãƒ¼ãƒ«")
    print("=" * 60)

    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆå¼•æ•°ãŒãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ï¼‰
    xml_path = sys.argv[1] if len(sys.argv) > 1 else "analyze_config.xml"

    try:
        config = AnalysisConfig.from_xml(xml_path)
    except Exception as e:
        print(f"âŒ è¨­å®šã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return

    # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    raw_file = config.raw_data_file
    if not raw_file or not os.path.exists(raw_file):
        print(f"âŒ ç”Ÿãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {raw_file}")
        print("\nåˆ©ç”¨å¯èƒ½ãªç”Ÿãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«:")
        available_files = FileUtils.find_available_data_files()
        for file_path in available_files:
            print(f"  {file_path}")
        return

    print(f"ğŸ“‚ ç”Ÿãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {config.raw_data_dir}")
    print(f"ğŸ“Š åˆ†æå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {raw_file}")
    print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {config.output_dir if config.output_dir else 'è‡ªå‹•ç”Ÿæˆ'}")
    print()

    # è§£æå®Ÿè¡Œ
    analyzer = SimulationDataAnalyzer(raw_file, config.output_dir)

    if analyzer.load_raw_data():
        analyzer.generate_all_visualizations(config)
        print(f"\nâœ… è§£æå®Œäº†! çµæœã¯ {analyzer.output_dir} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
    else:
        print("âŒ è§£æã‚’ä¸­æ­¢ã—ã¾ã—ãŸ")


if __name__ == "__main__":
    main()
