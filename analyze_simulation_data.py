"""
ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿãƒ‡ãƒ¼ã‚¿è§£æãƒ»å¯è¦–åŒ–å‡¦ç†

ç”Ÿãƒ‡ãƒ¼ã‚¿ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ã€
ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰ã¨åŒã˜å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã™ã‚‹
"""

# ===========================
# åˆ†æå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã®æŒ‡å®š
# ===========================
# ã“ã“ã«åˆ†æã—ãŸã„ç”Ÿãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„
RAW_DATA_FILE = "results/parsplice_20250912_155118/raw_simulation_data_parsplice_20250912_155118.json"

# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆNoneã®å ´åˆã¯è‡ªå‹•ç”Ÿæˆï¼‰
OUTPUT_DIR = None

import json
import os
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
import copy

# ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from src.config import SimulationConfig
from src.simulation.graph_generator import GraphGenerator
from src.visualization import TrajectoryVisualizer, SegmentStorageVisualizer
from src.utils import create_results_directory
from common import default_logger, get_file_timestamp


class SimulationDataAnalyzer:
    """ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿãƒ‡ãƒ¼ã‚¿è§£æãƒ»å¯è¦–åŒ–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, raw_data_file: str, output_dir: Optional[str] = None):
        self.raw_data_file = raw_data_file
        self.raw_data = None
        self.metadata = None
        self.step_data = None
        self.config = None
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
        if output_dir:
            self.output_dir = output_dir
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«analysis_ã‹ã‚‰å§‹ã¾ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
            base_dir = os.path.dirname(raw_data_file)
            timestamp = get_file_timestamp()
            self.output_dir = os.path.join(base_dir, f"analysis_{timestamp}")
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        os.makedirs(self.output_dir, exist_ok=True)
        
    def load_raw_data(self) -> bool:
        """ç”Ÿãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
        try:
            with open(self.raw_data_file, 'r', encoding='utf-8') as f:
                self.raw_data = json.load(f)
            
            self.metadata = self.raw_data['metadata']
            self.step_data = self.raw_data['step_data']
            
            # è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å¾©å…ƒ
            self.config = self._restore_config()
            
            print(f"âœ… ç”Ÿãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {self.raw_data_file}")
            print(f"   ã‚¹ãƒ†ãƒƒãƒ—æ•°: {len(self.step_data)}")
            print(f"   æˆ¦ç•¥: {self.metadata['config']['scheduling_strategy']}")
            print(f"   ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°: {self.metadata['config']['num_workers']}")
            print(f"   çŠ¶æ…‹æ•°: {self.metadata['config']['num_states']}")
            
            return True
            
        except Exception as e:
            print(f"âŒ ç”Ÿãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return False
    
    def _restore_config(self) -> SimulationConfig:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰SimulationConfigã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å¾©å…ƒ"""
        config_data = self.metadata['config']
        
        # SimulationConfigã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        config = SimulationConfig()
        
        # å±æ€§ã‚’è¨­å®š
        for key, value in config_data.items():
            setattr(config, key, value)
        
        return config
    
    def generate_all_visualizations(self) -> None:
        """å…¨ã¦ã®å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ"""
        print("\n=== å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆé–‹å§‹ ===")
        
        # è§£æãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
        analysis_data = self._prepare_analysis_data()
        
        # ã‚°ãƒ©ãƒ•ç”Ÿæˆå™¨ã‚’åˆæœŸåŒ–
        timestamp = self.metadata['timestamp']
        graph_generator = GraphGenerator(self.config, self.output_dir, timestamp)
        
        # 1. trajectoryé•·ã®æ¨ç§»ã‚°ãƒ©ãƒ•
        self._generate_trajectory_graph(graph_generator, analysis_data)
        
        # 2. total_valueé–¢é€£ã®ã‚°ãƒ©ãƒ•
        self._generate_total_value_graphs(graph_generator, analysis_data)
        
        # 3. è¡Œåˆ—å·®åˆ†ã®ã‚°ãƒ©ãƒ•
        self._generate_matrix_difference_graph(graph_generator, analysis_data)
        
        # 4. trajectoryå¯è¦–åŒ–ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³
        if self.config.trajectory_animation:
            self._generate_trajectory_animation(analysis_data)
        
        # 5. ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³
        if self.config.segment_storage_animation:
            self._generate_segment_storage_animation(analysis_data)
        
        # 6. ãƒ†ã‚­ã‚¹ãƒˆã‚µãƒãƒªãƒ¼
        self._generate_text_summary(analysis_data)
        
        print(f"âœ… å…¨ã¦ã®å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {self.output_dir}")
    
    def _prepare_analysis_data(self) -> Dict[str, Any]:
        """è§£æã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™"""
        trajectory_lengths = []
        total_values_per_worker = []
        trajectory_states_list = []
        step_logs = []
        
        # æ¨å®šç¢ºç‡é·ç§»è¡Œåˆ—ã®å±¥æ­´
        estimated_matrices = []
        true_matrix = np.array(self.metadata['transition_matrix'])
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„ãƒ‡ãƒ¼ã‚¿
        segment_storage_history = []
        
        for step_data in self.step_data:
            # trajectoryé•· (ãƒ‡ãƒ¼ã‚¿ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼ã§æ—¢ã«-1æ¸ˆã¿)
            trajectory_states = step_data['splicer']['trajectory']
            trajectory_length = step_data['splicer']['trajectory_length']  # ãƒ‡ãƒ¼ã‚¿ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼ã§è¨ˆç®—æ¸ˆã¿ã®å€¤ã‚’ä½¿ç”¨
            trajectory_lengths.append(trajectory_length)
            
            # trajectoryçŠ¶æ…‹
            trajectory_states_list.append(trajectory_states)
            
            # total_value per worker
            total_value = step_data['scheduler']['total_value']
            total_value_per_worker = total_value / self.config.num_workers if self.config.num_workers > 0 else 0
            total_values_per_worker.append(total_value_per_worker)
            
            # ã‚¹ãƒ†ãƒƒãƒ—ãƒ­ã‚°
            step_logs.append(step_data['step_log'])
            
            # æ¨å®šç¢ºç‡é·ç§»è¡Œåˆ—
            estimated_matrix = step_data['scheduler']['estimated_transition_matrix']
            if estimated_matrix:
                estimated_matrices.append(np.array(estimated_matrix))
            else:
                estimated_matrices.append(None)
            
            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
            segment_storage_record = self._prepare_segment_storage_record(step_data)
            segment_storage_history.append(segment_storage_record)
        
        return {
            'trajectory_lengths': trajectory_lengths,
            'total_values_per_worker': total_values_per_worker,
            'trajectory_states_list': trajectory_states_list,
            'step_logs': step_logs,
            'estimated_matrices': estimated_matrices,
            'true_matrix': true_matrix,
            'segment_storage_history': segment_storage_history
        }
    
    def _prepare_segment_storage_record(self, step_data: Dict) -> Dict[str, Any]:
        """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„å¯è¦–åŒ–ç”¨ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’æº–å‚™"""
        splicer_data = step_data['splicer']
        producer_data = step_data['producer']
        step_log = step_data['step_log']
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°æƒ…å ±
        segments_per_state = splicer_data['segment_store_info'].get('segments_per_state', {})
        
        # ã‚°ãƒ«ãƒ¼ãƒ—æƒ…å ±ã®å¤‰æ›
        group_info = {}
        for group_id, group_data in producer_data['group_details'].items():
            group_info[int(group_id)] = {
                'initial_state': group_data.get('initial_state'),
                'group_state': group_data.get('group_state'),
                'worker_ids': group_data.get('worker_ids', [])
            }
        
        # Spliceræƒ…å ±
        splicer_info = {
            'trajectory_length': splicer_data['trajectory_length'],
            'final_state': splicer_data['final_state'],
            'available_states': splicer_data['segment_store_info'].get('available_states', []),
            'used_segment_ids': splicer_data['segment_store_info'].get('used_segment_ids', {}),
            'total_used_segments': sum(len(ids) for ids in splicer_data['segment_store_info'].get('used_segment_ids', {}).values()),
            'states_with_segments': len(splicer_data['segment_store_info'].get('available_states', []))
        }
        
        return {
            'step': step_log['step'],
            'segments_per_state': segments_per_state,
            'group_info': group_info,
            'splicer_info': splicer_info,
            'total_segments': sum(segments_per_state.values())
        }
    
    def _generate_trajectory_graph(self, graph_generator: GraphGenerator, analysis_data: Dict) -> None:
        """trajectoryé•·ã®æ¨ç§»ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ"""
        print("  - trajectoryé•·æ¨ç§»ã‚°ãƒ©ãƒ•ç”Ÿæˆä¸­...")
        graph_generator.save_trajectory_graph(analysis_data['trajectory_lengths'])
    
    def _generate_total_value_graphs(self, graph_generator: GraphGenerator, analysis_data: Dict) -> None:
        """total_valueé–¢é€£ã®ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ"""
        print("  - total_valueé–¢é€£ã‚°ãƒ©ãƒ•ç”Ÿæˆä¸­...")
        graph_generator.save_total_value_graphs(
            analysis_data['total_values_per_worker'],
            analysis_data['trajectory_lengths']
        )
    
    def _generate_matrix_difference_graph(self, graph_generator: GraphGenerator, analysis_data: Dict) -> None:
        """è¡Œåˆ—å·®åˆ†ã®ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ"""
        print("  - è¡Œåˆ—å·®åˆ†ã‚°ãƒ©ãƒ•ç”Ÿæˆä¸­...")
        
        # selected_transition_matrix_historyã‹ã‚‰è¡Œåˆ—å·®åˆ†ã‚’è¨ˆç®—
        class DummyScheduler:
            def __init__(self, step_data):
                self.step_data = step_data
                # æœ€æ–°ã®çœŸã®é·ç§»è¡Œåˆ—ã‚’å–å¾—
                self.true_transition_matrix = None
                for step_info in reversed(step_data):
                    true_matrix = step_info['scheduler']['true_transition_matrix']
                    if true_matrix is not None:
                        self.true_transition_matrix = np.array(true_matrix)
                        break
            
            def calculate_matrix_differences(self):
                """ä¿å­˜ã•ã‚ŒãŸselected_transition_matrix_historyã‚’ä½¿ç”¨ã—ã¦è¡Œåˆ—å·®åˆ†ã‚’è¨ˆç®—"""
                if self.true_transition_matrix is None:
                    return []
                
                differences = []
                all_selected_matrices = []
                
                # å„ã‚¹ãƒ†ãƒƒãƒ—ã®selected_transition_matrix_historyã‚’åé›†
                for step_info in self.step_data:
                    history = step_info['scheduler'].get('selected_transition_matrix_history', [])
                    all_selected_matrices.extend(history)
                
                # é‡è¤‡ã‚’é™¤å»ï¼ˆåŒã˜stepã®ã‚¨ãƒ³ãƒˆãƒªã¯æœ€å¾Œã®ã‚‚ã®ã®ã¿ä½¿ç”¨ï¼‰
                unique_matrices = {}
                for history_entry in all_selected_matrices:
                    step = history_entry['step']
                    unique_matrices[step] = history_entry
                
                # stepã§ã‚½ãƒ¼ãƒˆã—ã¦å·®åˆ†ã‚’è¨ˆç®—
                for step in sorted(unique_matrices.keys()):
                    history_entry = unique_matrices[step]
                    selected_matrix = history_entry['matrix']
                    
                    # è¡Œåˆ—ã®å·®ã‚’è¨ˆç®—ï¼ˆãƒ•ãƒ­ãƒ™ãƒ‹ã‚¦ã‚¹ãƒãƒ«ãƒ ï¼‰
                    if isinstance(selected_matrix, list):
                        selected_matrix = np.array(selected_matrix)
                    
                    diff_matrix = self.true_transition_matrix - selected_matrix
                    frobenius_norm = np.linalg.norm(diff_matrix, 'fro')
                    
                    differences.append({
                        'step': step,
                        'frobenius_norm': frobenius_norm,
                        'max_absolute_diff': np.max(np.abs(diff_matrix))
                    })
                
                return differences
        
        dummy_scheduler = DummyScheduler(self.step_data)
        graph_generator.save_matrix_difference_graph(dummy_scheduler)
    
    def _generate_trajectory_animation(self, analysis_data: Dict) -> None:
        """trajectoryå¯è¦–åŒ–ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ"""
        print("  - trajectoryå¯è¦–åŒ–ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆä¸­...")
        
        # æœ€çµ‚ã®trajectoryçŠ¶æ…‹ã‚’å–å¾—
        if analysis_data['trajectory_states_list']:
            final_trajectory = analysis_data['trajectory_states_list'][-1]
            
            # TrajectoryVisualizerã‚’åˆæœŸåŒ–
            visualizer = TrajectoryVisualizer(self.config)
            visualizer.results_dir = self.output_dir
            visualizer.timestamp = self.metadata['timestamp']
            
            # trajectoryåº§æ¨™ã‚’è¨ˆç®—ï¼ˆç°¡å˜ãªãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯ï¼‰
            trajectory_coords = self._calculate_trajectory_coordinates(final_trajectory)
            
            # ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆ
            visualizer.create_trajectory_animation(trajectory_coords)
    
    def _generate_segment_storage_animation(self, analysis_data: Dict) -> None:
        """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ"""
        print("  - ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆä¸­...")
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„å±¥æ­´ã‚’ step_data ã‹ã‚‰æŠ½å‡º
        segment_storage_history = []
        for step_info in self.step_data:
            if 'segment_storage' in step_info:
                segment_storage_history.append(step_info['segment_storage'])
        
        if not segment_storage_history:
            print("    âš ï¸ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„å±¥æ­´ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            return
        
        # SegmentStorageVisualizerã‚’åˆæœŸåŒ–
        visualizer = SegmentStorageVisualizer(self.config)
        visualizer.results_dir = self.output_dir
        visualizer.timestamp = self.metadata['timestamp']
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„å±¥æ­´ã‚’è¨­å®š
        visualizer.segment_history = segment_storage_history
        
        # ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆ
        output_file = visualizer.create_segment_storage_animation()
        if output_file:
            print(f"    âœ… ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³: {os.path.basename(output_file)}")
        else:
            print("    âŒ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    def _calculate_trajectory_coordinates(self, trajectory_states: List[int]) -> List[tuple]:
        """trajectoryçŠ¶æ…‹ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯åº§æ¨™ã‚’è¨ˆç®—"""
        if not trajectory_states:
            return []
        
        coordinates = [(0, 0)]  # é–‹å§‹ä½ç½®
        x, y = 0, 0
        
        # ç°¡å˜ãªãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        np.random.seed(42)  # å†ç¾æ€§ã®ãŸã‚
        
        for i in range(1, len(trajectory_states)):
            # æ¬¡ã®åº§æ¨™ã‚’è¨ˆç®—ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ãªæ–¹å‘ï¼‰
            angle = np.random.uniform(0, 2 * np.pi)
            step_size = 1.0
            x += step_size * np.cos(angle)
            y += step_size * np.sin(angle)
            coordinates.append((x, y))
        
        return coordinates
    
    def _generate_text_summary(self, analysis_data: Dict) -> None:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ"""
        print("  - ãƒ†ã‚­ã‚¹ãƒˆã‚µãƒãƒªãƒ¼ç”Ÿæˆä¸­...")
        
        filename = os.path.join(
            self.output_dir,
            f'analysis_summary_{self.config.scheduling_strategy}_{self.metadata["timestamp"]}.txt'
        )
        
        with open(filename, 'w', encoding='utf-8') as f:
            self._write_analysis_header(f)
            self._write_analysis_configuration(f)
            self._write_analysis_step_logs(f, analysis_data)
            self._write_analysis_summary_statistics(f, analysis_data)
    
    def _write_analysis_header(self, f) -> None:
        """è§£æãƒ¬ãƒãƒ¼ãƒˆã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æ›¸ãè¾¼ã‚€"""
        f.write("ParSplice ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è§£æçµæœ\n")
        f.write("=" * 50 + "\n")
        f.write(f"è§£æå®Ÿè¡Œæ™‚åˆ»: {get_file_timestamp()}\n")
        f.write(f"å…ƒãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«: {os.path.basename(self.raw_data_file)}\n")
        f.write(f"å…ƒãƒ‡ãƒ¼ã‚¿å®Ÿè¡Œæ™‚åˆ»: {self.metadata['execution_time']}\n\n")
    
    def _write_analysis_configuration(self, f) -> None:
        """è¨­å®šæƒ…å ±ã‚’æ›¸ãè¾¼ã‚€"""
        config = self.metadata['config']
        f.write("ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š:\n")
        f.write(f"  æˆ¦ç•¥: {config['scheduling_strategy']}\n")
        f.write(f"  ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°: {config['num_workers']}\n")
        f.write(f"  çŠ¶æ…‹æ•°: {config['num_states']}\n")
        f.write(f"  ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ™‚é–“: {config['max_simulation_time']}\n")
        f.write(f"  ä¹±æ•°ã‚·ãƒ¼ãƒ‰: {config['random_seed']}\n\n")
    
    def _write_analysis_step_logs(self, f, analysis_data: Dict) -> None:
        """ã‚¹ãƒ†ãƒƒãƒ—ãƒ­ã‚°ã‚’æ›¸ãè¾¼ã‚€"""
        f.write("ã‚¹ãƒ†ãƒƒãƒ—ãƒ­ã‚°:\n")
        for step_log in analysis_data['step_logs']:
            f.write(f"Step {step_log['step']}: Splicer={step_log['splicer_result']}, "
                   f"Scheduler={step_log['scheduler_result']}, "
                   f"Trajectoryé•·={step_log['trajectory_length']}, "
                   f"æœ€çµ‚çŠ¶æ…‹={step_log['final_state']}, "
                   f"åé›†segments={step_log['segments_collected']}\n")
            
            # ParRepBoxè©³ç´°æƒ…å ±
            parrepbox_info = []
            for box_detail in step_log['parrepbox_details']:
                parrepbox_info.append(
                    f"G{box_detail['group_id']}({box_detail['state']}, "
                    f"åˆæœŸ:{box_detail['initial_state']}, {box_detail['workers']})"
                )
            
            if parrepbox_info:
                f.write(f"  ParRepBox: {' | '.join(parrepbox_info)}\n")
            else:
                f.write(f"  ParRepBox: ãªã—\n")
        f.write("\n")
    
    def _write_analysis_summary_statistics(self, f, analysis_data: Dict) -> None:
        """æ¦‚è¦çµ±è¨ˆã‚’æ›¸ãè¾¼ã‚€"""
        trajectory_lengths = analysis_data['trajectory_lengths']
        total_values = analysis_data['total_values_per_worker']
        
        f.write("æ¦‚è¦çµ±è¨ˆ:\n")
        f.write(f"  æœ€çµ‚trajectoryé•·: {trajectory_lengths[-1] if trajectory_lengths else 0}\n")
        f.write(f"  æœ€çµ‚total_value_per_worker: {total_values[-1] if total_values else 0:.6f}\n")
        f.write(f"  å¹³å‡trajectoryé•·: {np.mean(trajectory_lengths) if trajectory_lengths else 0:.2f}\n")
        f.write(f"  å¹³å‡total_value_per_worker: {np.mean(total_values) if total_values else 0:.6f}\n")
        f.write(f"  æœ€å¤§trajectoryé•·: {max(trajectory_lengths) if trajectory_lengths else 0}\n")
        f.write(f"  æœ€å¤§total_value_per_worker: {max(total_values) if total_values else 0:.6f}\n")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("=" * 60)
    print("ParSpliceç”Ÿãƒ‡ãƒ¼ã‚¿è§£æãƒ»å¯è¦–åŒ–ãƒ„ãƒ¼ãƒ«")
    print("=" * 60)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    if not os.path.exists(RAW_DATA_FILE):
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {RAW_DATA_FILE}")
        print("\nåˆ©ç”¨å¯èƒ½ãªç”Ÿãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«:")
        results_dir = "results"
        if os.path.exists(results_dir):
            for subdir in sorted(os.listdir(results_dir), reverse=True)[:5]:  # æœ€æ–°5ä»¶
                subdir_path = os.path.join(results_dir, subdir)
                if os.path.isdir(subdir_path):
                    json_files = list(Path(subdir_path).glob('raw_simulation_data_*.json'))
                    if json_files:
                        print(f"  {json_files[0]}")
        return
    
    print(f"ğŸ“Š åˆ†æå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {RAW_DATA_FILE}")
    print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {OUTPUT_DIR if OUTPUT_DIR else 'è‡ªå‹•ç”Ÿæˆ'}")
    print()
    
    # è§£æå®Ÿè¡Œ
    analyzer = SimulationDataAnalyzer(RAW_DATA_FILE, OUTPUT_DIR)
    
    if analyzer.load_raw_data():
        analyzer.generate_all_visualizations()
        print(f"\nâœ… è§£æå®Œäº†! çµæœã¯ {analyzer.output_dir} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
    else:
        print("âŒ è§£æã‚’ä¸­æ­¢ã—ã¾ã—ãŸ")


if __name__ == "__main__":
    main()
