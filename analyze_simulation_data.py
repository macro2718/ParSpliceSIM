"""
ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿãƒ‡ãƒ¼ã‚¿è§£æãƒ»å¯è¦–åŒ–å‡¦ç†

ç”Ÿãƒ‡ãƒ¼ã‚¿ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ã€
ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰ã¨åŒã˜å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã™ã‚‹
"""

# Standard library imports
import json
import gzip
import os
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional
try:
    import ijson  # optional: used for streaming parse
except Exception:
    ijson = None
import xml.etree.ElementTree as ET

# Third-party imports
import numpy as np

# Local imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from src.config import SimulationConfig
from src.simulation.graph_generator import GraphGenerator
from src.visualization import TrajectoryVisualizer, SegmentStorageVisualizer
from common import get_file_timestamp


class FileUtils:
    """ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¯ãƒ©ã‚¹"""
    
    @staticmethod
    def find_available_data_files(results_dir: str = "results", max_files: int = 5) -> List[Path]:
        """åˆ©ç”¨å¯èƒ½ãªç”Ÿãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ã™ã‚‹
        
        Args:
            results_dir: æ¤œç´¢å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            max_files: æœ€å¤§è¡¨ç¤ºä»¶æ•°
            
        Returns:
            List[Path]: è¦‹ã¤ã‹ã£ãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
        """
        files = []
        if os.path.exists(results_dir):
            for subdir in sorted(os.listdir(results_dir), reverse=True)[:max_files]:
                subdir_path = os.path.join(results_dir, subdir)
                if os.path.isdir(subdir_path):
                    # .json ã¨ .json.gz ã‚’ä¸¡å¯¾å¿œã§æ¢ç´¢ã—ã€æ–°ã—ã„æ–¹ã‚’æç¤º
                    candidates = []
                    candidates.extend(Path(subdir_path).glob('raw_simulation_data_*.json'))
                    candidates.extend(Path(subdir_path).glob('raw_simulation_data_*.json.gz'))
                    if candidates:
                        candidates.sort(key=lambda p: p.stat().st_mtime, reverse=True)
                        files.append(candidates[0])
        return files
    
    @staticmethod
    def load_json_data(file_path: str) -> Optional[Dict]:
        """JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        
        Args:
            file_path: JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            
        Returns:
            Optional[Dict]: èª­ã¿è¾¼ã¾ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã€å¤±æ•—æ™‚ã¯None
        """
        try:
            if str(file_path).endswith('.gz'):
                with gzip.open(file_path, 'rt', encoding='utf-8') as f:
                    return json.load(f)
            else:
                with open(file_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return None


class MatrixDifferenceCalculator:
    """è¡Œåˆ—å·®åˆ†è¨ˆç®—ã‚’æ‹…å½“ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, step_data: List[Dict]):
        self.step_data = step_data
        self.true_transition_matrix = self._extract_true_matrix()
    
    def _extract_true_matrix(self) -> Optional[np.ndarray]:
        """æœ€æ–°ã®çœŸã®é·ç§»è¡Œåˆ—ã‚’å–å¾—"""
        for step_info in reversed(self.step_data):
            true_matrix = step_info['scheduler']['true_transition_matrix']
            if true_matrix is not None:
                return np.array(true_matrix)
        return None
    
    def calculate_matrix_differences(self) -> List[Dict]:
        """ä¿å­˜ã•ã‚ŒãŸselected_transition_matrix_historyã‚’ä½¿ç”¨ã—ã¦è¡Œåˆ—å·®åˆ†ã‚’è¨ˆç®—"""
        if self.true_transition_matrix is None:
            return []

        # åŒä¸€stepã®ã‚¨ãƒ³ãƒˆãƒªã¯æœ€å¾Œã®ã‚‚ã®ã®ã¿ä½¿ç”¨ã™ã‚‹ãŸã‚ã€è¾æ›¸ã«ç›´æ¥é›†ç´„
        unique_matrices: Dict[int, Any] = {}
        for step_info in self.step_data:
            for entry in step_info['scheduler'].get('selected_transition_matrix_history', []) or []:
                step = entry.get('step')
                if step is not None:
                    unique_matrices[int(step)] = entry

        differences: List[Dict[str, Any]] = []
        for step in sorted(unique_matrices.keys()):
            selected_matrix = unique_matrices[step].get('matrix')
            if selected_matrix is None:
                continue
            if isinstance(selected_matrix, list):
                selected_matrix = np.array(selected_matrix)

            diff_matrix = self.true_transition_matrix - selected_matrix
            differences.append({
                'step': step,
                'frobenius_norm': np.linalg.norm(diff_matrix, 'fro'),
                'max_absolute_diff': np.max(np.abs(diff_matrix))
            })

        return differences


class AnalysisConfig:
    """è§£æè¨­å®šã‚¯ãƒ©ã‚¹

    - XMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è§£æè¨­å®šã‚’èª­ã¿è¾¼ã‚€
    - ç”Ÿãƒ‡ãƒ¼ã‚¿ã®å ´æ‰€ã¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§æŒ‡å®šï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä¾å­˜ã‚’å»ƒæ­¢ï¼‰
    - å„è§£æå‡ºåŠ›ï¼ˆã‚°ãƒ©ãƒ•/ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³/ã‚µãƒãƒªï¼‰ã‚’å€‹åˆ¥ã«åˆ¶å¾¡
    """

    def __init__(self) -> None:
        # å…¥åŠ›
        self.raw_data_dir: Optional[str] = None
        self.raw_data_file: Optional[str] = None  # å®Ÿéš›ã«ä½¿ç”¨ã™ã‚‹JSONãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆraw_data_dirã‹ã‚‰è‡ªå‹•æ¤œå‡ºï¼‰

        # å‡ºåŠ›
        self.output_dir: Optional[str] = None  # Noneã®å ´åˆã€è‡ªå‹•ç”Ÿæˆï¼ˆè§£æå®Ÿè¡Œæ™‚åˆ»ï¼‰

        # å‡ºåŠ›ãƒ•ãƒ©ã‚°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ã™ã¹ã¦æœ‰åŠ¹ï¼‰
        self.generate_trajectory_graph: bool = True
        self.generate_total_value_graphs: bool = True
        self.generate_matrix_difference_graph: bool = True
        self.generate_text_summary: bool = True
        self.generate_trajectory_animation: bool = False
        self.generate_segment_storage_animation: bool = True
        # é€æ¬¡è§£æï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
        self.streaming_parse: bool = False
        # ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³å€‹åˆ¥FPSï¼ˆ0ä»¥ä¸‹ã§è‡ªå‹•ï¼‰
        self.trajectory_animation_fps: int = 0
        self.segment_storage_animation_fps: int = 0

    @staticmethod
    def _to_bool(text: Optional[str], default: bool = True) -> bool:
        if text is None:
            return default
        return text.strip().lower() in {"1", "true", "yes", "on"}

    @classmethod
    def from_xml(cls, xml_path: str) -> "AnalysisConfig":
        """XMLè¨­å®šã‹ã‚‰ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç”Ÿæˆ"""
        config = cls()

        if not os.path.exists(xml_path):
            raise FileNotFoundError(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {xml_path}")

        tree = ET.parse(xml_path)
        root = tree.getroot()

        # å…¥åŠ›ï¼ˆç”Ÿãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª/ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
        input_node = root.find("input")
        if input_node is not None:
            raw_dir = input_node.findtext("raw_data_dir")
            config.raw_data_dir = raw_dir.strip() if raw_dir else None
            raw_file = input_node.findtext("raw_data_file")
            config.raw_data_file = raw_file.strip() if raw_file else None
            # ã‚ªãƒ—ã‚·ãƒ§ãƒ³
            options_node = input_node.find("options")
            if options_node is not None:
                streaming_text = options_node.findtext("streaming_parse")
                config.streaming_parse = cls._to_bool(streaming_text, False)

        # å‡ºåŠ›ï¼ˆæ˜ç¤ºæŒ‡å®šãŒã‚ã‚Œã°ä½¿ç”¨ï¼‰
        output_node = root.find("output")
        if output_node is not None:
            out_dir = output_node.findtext("dir")
            config.output_dir = out_dir.strip() if out_dir else None

        # å„å‡ºåŠ›ãƒ•ãƒ©ã‚°
        outputs_node = root.find("outputs")
        if outputs_node is not None:
            config.generate_trajectory_graph = cls._to_bool(outputs_node.findtext("trajectory_graph"), True)
            config.generate_total_value_graphs = cls._to_bool(outputs_node.findtext("total_value_graphs"), True)
            config.generate_matrix_difference_graph = cls._to_bool(outputs_node.findtext("matrix_difference_graph"), True)
            config.generate_text_summary = cls._to_bool(outputs_node.findtext("text_summary"), True)
            config.generate_trajectory_animation = cls._to_bool(outputs_node.findtext("trajectory_animation"), False)
            config.generate_segment_storage_animation = cls._to_bool(outputs_node.findtext("segment_storage_animation"), True)
            # å€‹åˆ¥FPSï¼ˆä»»æ„ï¼‰ã€‚ç„¡åŠ¹å€¤ã¯ç„¡è¦–ã€‚
            traj_fps_text = outputs_node.findtext("trajectory_animation_fps")
            if traj_fps_text is not None:
                try:
                    config.trajectory_animation_fps = int(traj_fps_text.strip())
                except Exception:
                    pass
            seg_fps_text = outputs_node.findtext("segment_storage_animation_fps")
            if seg_fps_text is not None:
                try:
                    config.segment_storage_animation_fps = int(seg_fps_text.strip())
                except Exception:
                    pass

        # raw_data_file ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚Œã°å„ªå…ˆ
        if config.raw_data_file:
            candidate_paths: List[Path] = []
            file_text = config.raw_data_file
            p = Path(file_text)
            if p.is_absolute():
                candidate_paths.append(p)
            else:
                # ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç›´ä¸‹
                candidate_paths.append(Path(file_text))
                # raw_data_dir ãŒã‚ã‚Œã°çµåˆ
                if config.raw_data_dir:
                    candidate_paths.append(Path(config.raw_data_dir) / file_text)

            resolved = None
            for cp in candidate_paths:
                if cp.exists():
                    resolved = cp
                    break
            if not resolved:
                raise FileNotFoundError(f"æŒ‡å®šã•ã‚ŒãŸ raw_data_file ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_text}")

            config.raw_data_file = str(resolved)
            # raw_data_dir ãŒæœªæŒ‡å®šãªã‚‰ã€ãƒ•ã‚¡ã‚¤ãƒ«ã®è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®š
            if not config.raw_data_dir:
                config.raw_data_dir = str(Path(config.raw_data_file).parent)
        else:
            # raw_data_dir ã‹ã‚‰ JSON ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç‰¹å®šï¼ˆè‡ªå‹•æ¤œå‡ºï¼‰
            if not config.raw_data_dir:
                raise ValueError("raw_data_dir ã‹ raw_data_file ã®ã©ã¡ã‚‰ã‹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
            if not os.path.isdir(config.raw_data_dir):
                raise NotADirectoryError(f"raw_data_dir ãŒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ã¯ã‚ã‚Šã¾ã›ã‚“: {config.raw_data_dir}")

            # .json / .json.gz ã‚’ä¸¡å¯¾å¿œã§æ¢ç´¢
            candidates = []
            candidates.extend(Path(config.raw_data_dir).glob("raw_simulation_data_*.json"))
            candidates.extend(Path(config.raw_data_dir).glob("raw_simulation_data_*.json.gz"))
            if not candidates:
                raise FileNotFoundError(
                    f"raw_data_dir ã«ç”Ÿãƒ‡ãƒ¼ã‚¿JSONãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config.raw_data_dir}"
                )
            # è¤‡æ•°ã‚ã‚‹å ´åˆã¯æœ€çµ‚æ›´æ–°ãŒæ–°ã—ã„ã‚‚ã®ã‚’æ¡ç”¨
            candidates.sort(key=lambda p: p.stat().st_mtime, reverse=True)
            config.raw_data_file = str(candidates[0])

        return config


class SimulationDataAnalyzer:
    """ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿãƒ‡ãƒ¼ã‚¿è§£æãƒ»å¯è¦–åŒ–ã‚¯ãƒ©ã‚¹
    
    Args:
        raw_data_file: è§£æå¯¾è±¡ã®ç”Ÿãƒ‡ãƒ¼ã‚¿JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆNoneã®å ´åˆã¯è‡ªå‹•ç”Ÿæˆï¼‰
    """
    
    def __init__(self, raw_data_file: str, output_dir: Optional[str] = None) -> None:
        self.raw_data_file: str = raw_data_file
        self.raw_data: Optional[Dict] = None
        self.metadata: Optional[Dict] = None
        self.step_data: Optional[List[Dict]] = None
        self.config: Optional[SimulationConfig] = None
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
        if output_dir:
            self.output_dir = output_dir
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«analysis_ã‹ã‚‰å§‹ã¾ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
            base_dir = os.path.dirname(raw_data_file)
            timestamp = get_file_timestamp()
            self.output_dir = os.path.join(base_dir, f"analysis_{timestamp}")
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        os.makedirs(self.output_dir, exist_ok=True)
        
    def load_raw_data(self) -> bool:
        """ç”Ÿãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        
        Returns:
            bool: èª­ã¿è¾¼ã¿æˆåŠŸæ™‚Trueã€å¤±æ•—æ™‚False
        """
        self.raw_data = FileUtils.load_json_data(self.raw_data_file)
        
        if self.raw_data is None:
            return False
        
        self.metadata = self.raw_data['metadata']
        self.step_data = self.raw_data['step_data']
        
        # è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å¾©å…ƒ
        self.config = self._restore_config()
        
        print(f"âœ… ç”Ÿãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {self.raw_data_file}")
        print(f"   ã‚¹ãƒ†ãƒƒãƒ—æ•°: {len(self.step_data)}")
        print(f"   æˆ¦ç•¥: {self.metadata['config']['scheduling_strategy']}")
        print(f"   ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°: {self.metadata['config']['num_workers']}")
        print(f"   çŠ¶æ…‹æ•°: {self.metadata['config']['num_states']}")
        
        return True
    
    def _restore_config(self) -> SimulationConfig:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰SimulationConfigã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å¾©å…ƒ
        
        Returns:
            SimulationConfig: å¾©å…ƒã•ã‚ŒãŸè¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        """
        config_data = self.metadata['config']
        
        # SimulationConfigã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        config = SimulationConfig()
        
        # å±æ€§ã‚’è¨­å®š
        for key, value in config_data.items():
            setattr(config, key, value)
        
        return config
    
    def generate_all_visualizations(self, config: AnalysisConfig) -> None:
        """å…¨ã¦ã®å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
        
        Args:
            config: è§£æè¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        """
        print("\n=== å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆé–‹å§‹ ===")
        
        # è§£æãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
        analysis_data = self._prepare_analysis_data()
        
        # ã‚°ãƒ©ãƒ•ç”Ÿæˆå™¨ã‚’åˆæœŸåŒ–
        timestamp = self.metadata['timestamp']
        graph_generator = GraphGenerator(self.config, self.output_dir, timestamp)
        
        # 1. trajectoryé•·ã®æ¨ç§»ã‚°ãƒ©ãƒ•
        if config.generate_trajectory_graph:
            self._generate_trajectory_graph(graph_generator, analysis_data)
        
        # 2. total_valueé–¢é€£ã®ã‚°ãƒ©ãƒ•
        if config.generate_total_value_graphs:
            self._generate_total_value_graphs(graph_generator, analysis_data)
        
        # 3. è¡Œåˆ—å·®åˆ†ã®ã‚°ãƒ©ãƒ•
        if config.generate_matrix_difference_graph:
            self._generate_matrix_difference_graph(graph_generator, analysis_data)
        
        # 4. trajectoryå¯è¦–åŒ–ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³
        if config.generate_trajectory_animation:
            # è§£æè¨­å®šã§fpsæŒ‡å®šãŒã‚ã‚Œã°ä¸Šæ›¸ã
            if getattr(config, 'trajectory_animation_fps', 0) and config.trajectory_animation_fps > 0:
                setattr(self.config, 'trajectory_animation_fps', int(config.trajectory_animation_fps))
            self._generate_trajectory_animation(analysis_data)
        
        # 5. ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³
        if config.generate_segment_storage_animation:
            # è§£æè¨­å®šã§fpsæŒ‡å®šãŒã‚ã‚Œã°ä¸Šæ›¸ã
            if getattr(config, 'segment_storage_animation_fps', 0) and config.segment_storage_animation_fps > 0:
                setattr(self.config, 'segment_storage_animation_fps', int(config.segment_storage_animation_fps))
            self._generate_segment_storage_animation(analysis_data)
        
        # 6. ãƒ†ã‚­ã‚¹ãƒˆã‚µãƒãƒªãƒ¼
        if config.generate_text_summary:
            self._generate_text_summary(analysis_data)
        
        print(f"âœ… å…¨ã¦ã®å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {self.output_dir}")
    
    def _prepare_analysis_data(self) -> Dict[str, Any]:
        """è§£æã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
        
        Returns:
            Dict[str, Any]: è§£æç”¨ãƒ‡ãƒ¼ã‚¿ã®è¾æ›¸
        """
        trajectory_data = self._extract_trajectory_data()
        matrix_data = self._extract_matrix_data()
        segment_data = self._extract_segment_storage_data()
        
        return {
            **trajectory_data,
            **matrix_data,
            **segment_data
        }
    
    def _extract_trajectory_data(self) -> Dict[str, List]:
        """trajectoryã«é–¢é€£ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        
        Returns:
            Dict[str, List]: trajectoryé–¢é€£ãƒ‡ãƒ¼ã‚¿ã®è¾æ›¸
        """
        trajectory_lengths = []
        total_values_per_worker = []
        trajectory_states_list = []
        step_logs = []
        
        for step_data in self.step_data:
            # trajectoryé•· (ãƒ‡ãƒ¼ã‚¿ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼ã§æ—¢ã«-1æ¸ˆã¿)
            trajectory_states = step_data['splicer']['trajectory']
            trajectory_length = step_data['splicer']['trajectory_length']
            trajectory_lengths.append(trajectory_length)
            
            # trajectoryçŠ¶æ…‹
            trajectory_states_list.append(trajectory_states)
            
            # total_value per worker
            total_value = step_data['scheduler']['total_value']
            total_value_per_worker = total_value / self.config.num_workers if self.config.num_workers > 0 else 0
            total_values_per_worker.append(total_value_per_worker)
            
            # ã‚¹ãƒ†ãƒƒãƒ—ãƒ­ã‚°
            step_logs.append(step_data['step_log'])
        
        return {
            'trajectory_lengths': trajectory_lengths,
            'total_values_per_worker': total_values_per_worker,
            'trajectory_states_list': trajectory_states_list,
            'step_logs': step_logs
        }
    
    def _extract_matrix_data(self) -> Dict[str, Any]:
        """é·ç§»è¡Œåˆ—ã«é–¢é€£ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        
        Returns:
            Dict[str, Any]: é·ç§»è¡Œåˆ—é–¢é€£ãƒ‡ãƒ¼ã‚¿ã®è¾æ›¸
        """
        estimated_matrices = []
        true_matrix = np.array(self.metadata['transition_matrix'])
        
        for step_data in self.step_data:
            # æ¨å®šç¢ºç‡é·ç§»è¡Œåˆ—
            estimated_matrix = step_data['scheduler']['estimated_transition_matrix']
            if estimated_matrix:
                estimated_matrices.append(np.array(estimated_matrix))
            else:
                estimated_matrices.append(None)
        
        return {
            'estimated_matrices': estimated_matrices,
            'true_matrix': true_matrix
        }
    
    def _extract_segment_storage_data(self) -> Dict[str, List]:
        """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„ã«é–¢é€£ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        
        Returns:
            Dict[str, List]: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„é–¢é€£ãƒ‡ãƒ¼ã‚¿ã®è¾æ›¸
        """
        segment_storage_history = []
        
        for step_data in self.step_data:
            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
            segment_storage_record = self._prepare_segment_storage_record(step_data)
            segment_storage_history.append(segment_storage_record)
        
        return {
            'segment_storage_history': segment_storage_history
        }
    
    def _prepare_segment_storage_record(self, step_data: Dict) -> Dict[str, Any]:
        """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„å¯è¦–åŒ–ç”¨ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’æº–å‚™"""
        splicer_data = step_data['splicer']
        producer_data = step_data['producer']
        step_log = step_data['step_log']
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°æƒ…å ±ï¼ˆã‚­ãƒ¼ãŒæ–‡å­—åˆ—åŒ–ã•ã‚Œã¦ã„ã‚‹å ´åˆãŒã‚ã‚‹ãŸã‚æ•´æ•°åŒ–ï¼‰
        segments_per_state_raw = splicer_data['segment_store_info'].get('segments_per_state', {})
        if isinstance(segments_per_state_raw, dict):
            segments_per_state = {int(k): int(v) for k, v in segments_per_state_raw.items()}
        else:
            segments_per_state = {}
        
        # ã‚°ãƒ«ãƒ¼ãƒ—æƒ…å ±ã®å¤‰æ›ï¼ˆå¯è¦–åŒ–å´ã®æœŸå¾…ã‚­ãƒ¼ã«åˆã‚ã›ã‚‹: 'state'ï¼‰
        group_info = {}
        for group_id, group_data in producer_data['group_details'].items():
            group_info[int(group_id)] = {
                'initial_state': group_data.get('initial_state'),
                'state': group_data.get('group_state'),  # å¯è¦–åŒ–ã§å‚ç…§ã•ã‚Œã‚‹ã‚­ãƒ¼åã«çµ±ä¸€
                'worker_ids': group_data.get('worker_ids', [])
            }
        
        # Spliceræƒ…å ±ï¼ˆused_segment_ids ã‚‚ã‚­ãƒ¼æ•´æ•°åŒ–ï¼‰
        used_ids_raw = splicer_data['segment_store_info'].get('used_segment_ids', {})
        used_ids = {int(k): v for k, v in used_ids_raw.items()} if isinstance(used_ids_raw, dict) else {}

        splicer_info = {
            'trajectory_length': splicer_data['trajectory_length'],
            'final_state': splicer_data['final_state'],
            'available_states': splicer_data['segment_store_info'].get('available_states', []),
            'used_segment_ids': used_ids,
            'total_used_segments': sum(len(ids) for ids in used_ids.values()),
            'states_with_segments': len(splicer_data['segment_store_info'].get('available_states', []))
        }
        
        return {
            'step': step_log['step'],
            'segments_per_state': segments_per_state,
            'group_info': group_info,
            'splicer_info': splicer_info,
            'total_segments': sum(segments_per_state.values())
        }
    
    def _generate_trajectory_graph(self, graph_generator: GraphGenerator, analysis_data: Dict) -> None:
        """trajectoryé•·ã®æ¨ç§»ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ"""
        print("  - trajectoryé•·æ¨ç§»ã‚°ãƒ©ãƒ•ç”Ÿæˆä¸­...")
        graph_generator.save_trajectory_graph(analysis_data['trajectory_lengths'])
    
    def _generate_total_value_graphs(self, graph_generator: GraphGenerator, analysis_data: Dict) -> None:
        """total_valueé–¢é€£ã®ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ"""
        print("  - total_valueé–¢é€£ã‚°ãƒ©ãƒ•ç”Ÿæˆä¸­...")
        graph_generator.save_total_value_graphs(
            analysis_data['total_values_per_worker'],
            analysis_data['trajectory_lengths']
        )
    
    def _generate_matrix_difference_graph(self, graph_generator: GraphGenerator, analysis_data: Dict) -> None:
        """è¡Œåˆ—å·®åˆ†ã®ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ"""
        print("  - è¡Œåˆ—å·®åˆ†ã‚°ãƒ©ãƒ•ç”Ÿæˆä¸­...")

        # MatrixDifferenceCalculatorã‚’ä½¿ç”¨ã—ã¦è¡Œåˆ—å·®åˆ†ã‚’è¨ˆç®—
        calculator = MatrixDifferenceCalculator(self.step_data)
        graph_generator.save_matrix_difference_graph(calculator)

    # ===== é€æ¬¡è§£æï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰å¯¾å¿œ =====
    def load_and_generate_streaming(self, config: AnalysisConfig) -> bool:
        """ijson ã‚’ä½¿ã£ã¦é€æ¬¡ã«è§£æãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰ã—ã€å¯è¦–åŒ–ã‚’ç”Ÿæˆã™ã‚‹ã€‚
        å‡ºåŠ›ä»•æ§˜ã¯å¾“æ¥ã¨åŒä¸€ã€‚
        """
        if ijson is None:
            print("âš ï¸ ijson ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚é€šå¸¸ã®å…¨èª­ã¿è¾¼ã¿ãƒ¢ãƒ¼ãƒ‰ã§è§£æã—ã¾ã™ã€‚")
            return False

        print("ğŸŒ€ é€æ¬¡è§£æãƒ¢ãƒ¼ãƒ‰ã§èª­ã¿è¾¼ã¿ä¸­ï¼ˆijsonï¼‰...")

        # 1) ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆåˆ¥ãƒ‘ã‚¹ã§è»½é‡ã«ï¼‰
        try:
            if str(self.raw_data_file).endswith('.gz'):
                with gzip.open(self.raw_data_file, 'rt', encoding='utf-8') as f:
                    for meta in ijson.items(f, 'metadata'):
                        self.metadata = meta
                        break
            else:
                with open(self.raw_data_file, 'r', encoding='utf-8') as f:
                    for meta in ijson.items(f, 'metadata'):
                        self.metadata = meta
                        break
        except Exception as e:
            print(f"âŒ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆé€æ¬¡è§£æï¼‰: {e}")
            return False

        if not self.metadata:
            print("âŒ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆé€æ¬¡è§£æï¼‰")
            return False

        # è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å¾©å…ƒ
        self.config = self._restore_config()

        # 2) ã‚¹ãƒ†ãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ã‚’é€æ¬¡å‡¦ç†ã—ã€å¿…è¦ãªæ´¾ç”Ÿãƒ‡ãƒ¼ã‚¿ã®ã¿è“„ç©
        trajectory_lengths: List[int] = []
        total_values_per_worker: List[float] = []
        trajectory_states_list: List[List[int]] = []
        step_logs: List[Dict[str, Any]] = []
        segment_storage_history: List[Dict[str, Any]] = []

        # è¡Œåˆ—å·®åˆ†ç”¨ã®å±¥æ­´ï¼ˆåŒä¸€stepã¯æœ€å¾Œã®ã¿ï¼‰
        unique_selected_matrices: Dict[int, Any] = {}
        true_matrix = np.array(self.metadata['transition_matrix']) if self.metadata.get('transition_matrix') is not None else None

        try:
            if str(self.raw_data_file).endswith('.gz'):
                fp = gzip.open(self.raw_data_file, 'rt', encoding='utf-8')
            else:
                fp = open(self.raw_data_file, 'r', encoding='utf-8')
            with fp as f:
                for step_obj in ijson.items(f, 'step_data.item'):
                    # trajectoryé–¢é€£
                    splicer_data = step_obj['splicer']
                    trajectory_states = splicer_data.get('trajectory', [])
                    trajectory_states_list.append(trajectory_states)
                    trajectory_lengths.append(splicer_data.get('trajectory_length', 0))

                    # total_value per worker
                    sched = step_obj['scheduler']
                    total_value = sched.get('total_value', 0)
                    n_workers = self.metadata['config'].get('num_workers', self.config.num_workers)
                    total_values_per_worker.append((total_value / n_workers) if n_workers else 0)

                    # ã‚¹ãƒ†ãƒƒãƒ—ãƒ­ã‚°
                    if 'step_log' in step_obj:
                        step_logs.append(step_obj['step_log'])

                    # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ç”¨
                    segment_storage_history.append(self._prepare_segment_storage_record(step_obj))

                    # è¡Œåˆ—å·®åˆ†ç”¨å±¥æ­´
                    history = sched.get('selected_transition_matrix_history', [])
                    for entry in history:
                        s = entry.get('step')
                        if s is not None:
                            unique_selected_matrices[int(s)] = entry
        except Exception as e:
            print(f"âŒ é€æ¬¡è§£æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return False

        # è¡Œåˆ—å·®åˆ†ã®è¨ˆç®—ã‚’äº‹å¾Œã«ã¾ã¨ã‚ã¦
        matrix_differences: List[Dict[str, Any]] = []
        if true_matrix is not None and unique_selected_matrices:
            for step in sorted(unique_selected_matrices.keys()):
                entry = unique_selected_matrices[step]
                selected_matrix = entry.get('matrix')
                if isinstance(selected_matrix, list):
                    selected_matrix = np.array(selected_matrix)
                if selected_matrix is not None:
                    diff_matrix = true_matrix - selected_matrix
                    matrix_differences.append({
                        'step': step,
                        'frobenius_norm': np.linalg.norm(diff_matrix, 'fro'),
                        'max_absolute_diff': np.max(np.abs(diff_matrix))
                    })

        class PrecomputedMatrixDifferenceCalculator:
            def __init__(self, diffs: List[Dict[str, Any]]):
                self._diffs = diffs
            def calculate_matrix_differences(self) -> List[Dict[str, Any]]:
                return self._diffs

        # å¯è¦–åŒ–ç”Ÿæˆ
        timestamp = self.metadata['timestamp']
        graph_generator = GraphGenerator(self.config, self.output_dir, timestamp)

        print("\n=== å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆé–‹å§‹ï¼ˆé€æ¬¡è§£æï¼‰ ===")
        if config.generate_trajectory_graph:
            self._generate_trajectory_graph(graph_generator, {
                'trajectory_lengths': trajectory_lengths
            })
        if config.generate_total_value_graphs:
            self._generate_total_value_graphs(graph_generator, {
                'total_values_per_worker': total_values_per_worker,
                'trajectory_lengths': trajectory_lengths
            })
        if config.generate_matrix_difference_graph:
            graph_generator.save_matrix_difference_graph(PrecomputedMatrixDifferenceCalculator(matrix_differences))
        if config.generate_trajectory_animation and trajectory_states_list and true_matrix is not None:
            # è§£æè¨­å®šã§fpsæŒ‡å®šãŒã‚ã‚Œã°ä¸Šæ›¸ã
            if getattr(config, 'trajectory_animation_fps', 0) and config.trajectory_animation_fps > 0:
                setattr(self.config, 'trajectory_animation_fps', int(config.trajectory_animation_fps))
            self._generate_trajectory_animation({'trajectory_states_list': trajectory_states_list, 'true_matrix': true_matrix})
        if config.generate_segment_storage_animation:
            # è§£æè¨­å®šã§fpsæŒ‡å®šãŒã‚ã‚Œã°ä¸Šæ›¸ã
            if getattr(config, 'segment_storage_animation_fps', 0) and config.segment_storage_animation_fps > 0:
                setattr(self.config, 'segment_storage_animation_fps', int(config.segment_storage_animation_fps))
            self._generate_segment_storage_animation({'segment_storage_history': segment_storage_history})
        if config.generate_text_summary:
            self._generate_text_summary({
                'trajectory_lengths': trajectory_lengths,
                'total_values_per_worker': total_values_per_worker,
                'step_logs': step_logs
            })

        print(f"âœ… å…¨ã¦ã®å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {self.output_dir}")
        return True
    
    def _generate_trajectory_animation(self, analysis_data: Dict) -> None:
        """trajectoryå¯è¦–åŒ–ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ"""
        print("  - trajectoryå¯è¦–åŒ–ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆä¸­...")
        
        # trajectoryçŠ¶æ…‹å±¥æ­´ã¨é·ç§»è¡Œåˆ—ã‚’å–å¾—
        if analysis_data['trajectory_states_list'] and analysis_data['true_matrix'] is not None:
            trajectory_states_history = analysis_data['trajectory_states_list']
            transition_matrix = analysis_data['true_matrix']
            
            # TrajectoryVisualizerã‚’åˆæœŸåŒ–
            visualizer = TrajectoryVisualizer(self.config)
            visualizer.results_dir = self.output_dir
            visualizer.timestamp = self.metadata['timestamp']
            
            # ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆ
            visualizer.create_trajectory_animation(trajectory_states_history, transition_matrix)
    
    def _generate_segment_storage_animation(self, analysis_data: Dict) -> None:
        """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ"""
        print("  - ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆä¸­...")
        
        def _normalize_history(entries: List[Dict]) -> List[Dict]:
            normed = []
            for rec in entries:
                d = dict(rec)
                sps = d.get('segments_per_state', {})
                if isinstance(sps, dict):
                    d['segments_per_state'] = {int(k): int(v) for k, v in sps.items()}
                normed.append(d)
            return normed

        # é€æ¬¡è§£æã§äº‹å‰è¨ˆç®—ã•ã‚ŒãŸå±¥æ­´ãŒã‚ã‚Œã°å„ªå…ˆ
        if analysis_data and 'segment_storage_history' in analysis_data and analysis_data['segment_storage_history']:
            segment_storage_history = _normalize_history(analysis_data['segment_storage_history'])
        else:
            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„å±¥æ­´ã‚’ step_data ã‹ã‚‰æŠ½å‡º
            segment_storage_history = []
            for step_info in self.step_data:
                if 'segment_storage' in step_info:
                    segment_storage_history.append(step_info['segment_storage'])
            segment_storage_history = _normalize_history(segment_storage_history)
        
        if not segment_storage_history:
            print("    âš ï¸ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„å±¥æ­´ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            return
        
        # SegmentStorageVisualizerã‚’åˆæœŸåŒ–
        visualizer = SegmentStorageVisualizer(self.config)
        visualizer.results_dir = self.output_dir
        visualizer.timestamp = self.metadata['timestamp']
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„å±¥æ­´ã‚’è¨­å®š
        visualizer.segment_history = segment_storage_history
        
        # ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆ
        output_file = visualizer.create_segment_storage_animation()
        if output_file:
            print(f"    âœ… ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³: {os.path.basename(output_file)}")
        else:
            print("    âŒ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè²¯è“„ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    def _generate_text_summary(self, analysis_data: Dict) -> None:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ"""
        print("  - ãƒ†ã‚­ã‚¹ãƒˆã‚µãƒãƒªãƒ¼ç”Ÿæˆä¸­...")
        
        filename = os.path.join(
            self.output_dir,
            f'analysis_summary_{self.config.scheduling_strategy}_{self.metadata["timestamp"]}.txt'
        )
        
        with open(filename, 'w', encoding='utf-8') as f:
            self._write_analysis_header(f)
            self._write_analysis_configuration(f)
            self._write_analysis_step_logs(f, analysis_data)
            self._write_analysis_summary_statistics(f, analysis_data)
    
    def _write_analysis_header(self, f) -> None:
        """è§£æãƒ¬ãƒãƒ¼ãƒˆã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æ›¸ãè¾¼ã‚€"""
        f.write("ParSplice ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è§£æçµæœ\n")
        f.write("=" * 50 + "\n")
        f.write(f"è§£æå®Ÿè¡Œæ™‚åˆ»: {get_file_timestamp()}\n")
        f.write(f"å…ƒãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«: {os.path.basename(self.raw_data_file)}\n")
        f.write(f"å…ƒãƒ‡ãƒ¼ã‚¿å®Ÿè¡Œæ™‚åˆ»: {self.metadata['execution_time']}\n\n")
    
    def _write_analysis_configuration(self, f) -> None:
        """è¨­å®šæƒ…å ±ã‚’æ›¸ãè¾¼ã‚€"""
        config = self.metadata['config']
        f.write("ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š:\n")
        f.write(f"  æˆ¦ç•¥: {config['scheduling_strategy']}\n")
        f.write(f"  ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°: {config['num_workers']}\n")
        f.write(f"  çŠ¶æ…‹æ•°: {config['num_states']}\n")
        f.write(f"  ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ™‚é–“: {config['max_simulation_time']}\n")
        f.write(f"  ä¹±æ•°ã‚·ãƒ¼ãƒ‰: {config['random_seed']}\n\n")
    
    def _write_analysis_step_logs(self, f, analysis_data: Dict) -> None:
        """ã‚¹ãƒ†ãƒƒãƒ—ãƒ­ã‚°ã‚’æ›¸ãè¾¼ã‚€"""
        f.write("ã‚¹ãƒ†ãƒƒãƒ—ãƒ­ã‚°:\n")
        for step_log in analysis_data['step_logs']:
            f.write(f"Step {step_log['step']}: Splicer={step_log['splicer_result']}, "
                   f"Scheduler={step_log['scheduler_result']}, "
                   f"Trajectoryé•·={step_log['trajectory_length']}, "
                   f"æœ€çµ‚çŠ¶æ…‹={step_log['final_state']}, "
                   f"åé›†segments={step_log['segments_collected']}\n")
            
            # ParRepBoxè©³ç´°æƒ…å ±
            parrepbox_info = []
            for box_detail in step_log['parrepbox_details']:
                parrepbox_info.append(
                    f"G{box_detail['group_id']}({box_detail['state']}, "
                    f"åˆæœŸ:{box_detail['initial_state']}, {box_detail['workers']})"
                )
            
            if parrepbox_info:
                f.write(f"  ParRepBox: {' | '.join(parrepbox_info)}\n")
            else:
                f.write(f"  ParRepBox: ãªã—\n")
        f.write("\n")
    
    def _write_analysis_summary_statistics(self, f, analysis_data: Dict) -> None:
        """æ¦‚è¦çµ±è¨ˆã‚’æ›¸ãè¾¼ã‚€"""
        trajectory_lengths = analysis_data['trajectory_lengths']
        total_values = analysis_data['total_values_per_worker']
        
        f.write("æ¦‚è¦çµ±è¨ˆ:\n")
        f.write(f"  æœ€çµ‚trajectoryé•·: {trajectory_lengths[-1] if trajectory_lengths else 0}\n")
        f.write(f"  æœ€çµ‚total_value_per_worker: {total_values[-1] if total_values else 0:.6f}\n")
        f.write(f"  å¹³å‡trajectoryé•·: {np.mean(trajectory_lengths) if trajectory_lengths else 0:.2f}\n")
        f.write(f"  å¹³å‡total_value_per_worker: {np.mean(total_values) if total_values else 0:.6f}\n")
        f.write(f"  æœ€å¤§trajectoryé•·: {max(trajectory_lengths) if trajectory_lengths else 0}\n")
        f.write(f"  æœ€å¤§total_value_per_worker: {max(total_values) if total_values else 0:.6f}\n")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("=" * 60)
    print("ParSpliceç”Ÿãƒ‡ãƒ¼ã‚¿è§£æãƒ»å¯è¦–åŒ–ãƒ„ãƒ¼ãƒ«")
    print("=" * 60)

    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆå¼•æ•°ãŒãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ï¼‰
    xml_path = sys.argv[1] if len(sys.argv) > 1 else "analyze_config.xml"

    try:
        config = AnalysisConfig.from_xml(xml_path)
    except Exception as e:
        print(f"âŒ è¨­å®šã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return

    # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    raw_file = config.raw_data_file
    if not raw_file or not os.path.exists(raw_file):
        print(f"âŒ ç”Ÿãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {raw_file}")
        print("\nåˆ©ç”¨å¯èƒ½ãªç”Ÿãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«:")
        available_files = FileUtils.find_available_data_files()
        for file_path in available_files:
            print(f"  {file_path}")
        return

    print(f"ğŸ“‚ ç”Ÿãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {config.raw_data_dir}")
    print(f"ğŸ“Š åˆ†æå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {raw_file}")
    print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {config.output_dir if config.output_dir else 'è‡ªå‹•ç”Ÿæˆ'}")
    print()

    # è§£æå®Ÿè¡Œ
    analyzer = SimulationDataAnalyzer(raw_file, config.output_dir)

    if config.streaming_parse and ijson is not None:
        ok = analyzer.load_and_generate_streaming(config)
        if ok:
            print(f"\nâœ… è§£æå®Œäº†! çµæœã¯ {analyzer.output_dir} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
            return
        else:
            print("âš ï¸ é€æ¬¡è§£æã«å¤±æ•—ã¾ãŸã¯åˆ©ç”¨ä¸å¯ã®ãŸã‚ã€é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã¸ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™ã€‚")

    if analyzer.load_raw_data():
        analyzer.generate_all_visualizations(config)
        print(f"\nâœ… è§£æå®Œäº†! çµæœã¯ {analyzer.output_dir} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
    else:
        print("âŒ è§£æã‚’ä¸­æ­¢ã—ã¾ã—ãŸ")


if __name__ == "__main__":
    main()
